aes(x=date, y=unemploy)) +
geom_line()
ggplot(data=economics,
aes(x=date, y=unemploy)) +
geom_point(color = "red") +
geom_line()
library(ggplot2)
library(dplyr)
df <- as.data.frame(mpg)
ggplot(data=df,
aes(x=drv, y=hwy)) +
geom_boxplot()
df <- economics
head(df)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line()
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line() +
geom_abline(intercept=12.1, slope=-0.0003444)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line() +
geom_hline(yintercept=mean(df$psavert))
tmp <-
df %>% filter(psavert == min(psavert)) %>%
select(date)
tmp <- as.data.frame(tmp)$date
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line() +
geom_vline(xintercept = tmp)
tmp <- as.data.frame(tmp)
tmp
tmp <- as.data.frame(tmp)$date
tmp <- as.data.frame(tmp)$date
tmp <-
df %>% filter(psavert == min(psavert)) %>%
select(date)
tmp <- as.data.frame(tmp)$date
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line() +
geom_vline(xintercept = tmp)
## 만약 날짜를 직접입력하려면??
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_line() +
geom_vline(xintercept = as.Date("2009-10-01"))
# geom_text(aes(label="라벨명", vjust=세로위치, hjust=가로위치)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
geom_text(aes(label=psavert, vjust=0, hjust=-0.5))
# annotate("모양",
#          xmin=x축시작,
#          xmax=x축 끝,
#          ymin=y축 시작,
#          ymax=y축 끝)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
annotate("rect",
xmin=as.Date("1991-01-01"),
xmax=as.Date("1991-12-31"),
ymin=8,
ymax=9,
alpha=0.3,
fill="red")
# geom_text(aes(label="라벨명", vjust=세로위치, hjust=가로위치)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
geom_text(aes(label=psavert, vjust=0, hjust=-0.5))
# annotate("모양",
#          xmin=x축시작,
#          xmax=x축 끝,
#          ymin=y축 시작,
#          ymax=y축 끝)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
annotate("rect",
xmin=as.Date("1991-01-01"),
xmax=as.Date("1991-12-31"),
ymin=8,
ymax=9,
alpha=0.3,
fill="red")
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
annotate("rect",
xmin=as.Date("1991-01-01"),
xmax=as.Date("1991-12-31"),
ymin=8,
ymax=9,
alpha=0.3,
fill="red") +
annotate("segment",
x = as.Date("1990-05-01"),
xend=as.Date("1991-05-01"),
y = 7.5,
yend=8.5,
color="blue",
arrow=arrow()) +
annotate("text",
x=as.Date("1991-05-01"),
y=8.5,
label="글자도 쓸수 있어요!!")
# labs(x=x축 이름, y=y축 이름, title=그래프 제목)
ggplot(data=df,
aes(x=date, y=psavert)) +
geom_point() +
xlim(as.Date("1990-01-01"),
as.Date("1992-12-01")) +
ylim(7,10) +
labs(x="연도", y="개인저축률", title="날짜별 개인 저축률") +
theme_classic()
df <- read.csv(file.choose(),
sheetIndex = 1,
encoding = "UTF-8")
df <- read.csv(file.choose(),
encoding = "UTF-8")
df
class(df)
str(df)
#nrow로 행의 갯수를 세고, 이를통해 랜덤한 숫자를 추출하고, 이를 바탕으로 랭킹을 매겨본뒤,
#다시한번 무작위로 뒤섞인 데이터를 저장하는 과정입니다.
#이렇게 랜덤하게 섞는 방법을 이용하면, 샘플링할때도 단순하게 위에서 몇개는 훈련용, 그 나머지는 테스트용으로 간단하게 나눠볼수 있습니다.
df <- df[order(runif(nrow(df))),]
index <- sample(1:nrow(df), nrow(df) * 0.7, replace = F)
train <- df[index,]
train <- df[-index,]
train <- df[index,]
test <- df[-index,]
#C5.0으로 모델 만들기
library(C50)
credit_model <- C5.0(within(train, rm(default)), train$default)
credit_train$default<-as.factor(credit_train$default)
credit_train$default<-as.factor(train$default)
train$default<-as.factor(train$default)
credit_model <- C5.0(within(train, rm(default)), train$default)
table(test$default,predict(credit_model,newdata=test))
result=predict(credit_model,newdata=test)
result<-predict(credit_model,newdata=test)
Confusion_Matrix<-table(test$default, result) # 오른쪽이 정답, 왼쪽이 예측한 결과
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy
mm <- ctree(default ~ . , data = train)
mm <- tree(default ~ . , data = train)
mm <- rpart(default ~ . , data = train)
#rpart 패키지 이용하기.
library(party)
#rpart 패키지 이용하기.
library(rpart)
mm <- rpart(default ~ . , data = train)
plot(mm)
rpart.plot(mm)
library(rpart.plot)
rpart.plot(mm)
result2<-predict(credit_model,newdata=test)
Confusion_Matrix<-table(test$default, result2) # 오른쪽이 정답, 왼쪽이 예측한 결과
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy
library(C50)
####### Train, Test 80%, 20%로 나눈다.
set.seed(2020)
idx <- sample(1:nrow(iris), size=nrow(iris)*0.8)
D.train<-iris[idx, ]
D.test<-iris[-idx, ]
############# c5.0 모델 구축
model<-C5.0(Species~., data = D.train)  #.(dot)은 or 이란 뜻이다.  Species변수를 제외한 모든변수
result<-predict(object=model, newdata = D.test)
Confusion_Matrix<-table(D.test$Species, result) # 오른쪽이 정답, 왼쪽이 예측한 결과
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy
Accuracy<-Accuracy*100
Accuracy
Accuracy
View(D.test)
rm(list=())
rm(list=() )
setwd("C:/Users/kyeon/OneDrive/바탕 화면/빅데이터/R/앙상블")
rm(list = ls())
for(i in 1:6){
+ result=2*i
+ print(result)
+}
for(i in 1:6){
+ result=2*i
+ print(result)
+
}
+ result=2*i
print(result)
result<-2*i
i=1
for(i in 1:6){
result<-2*i
print(result)
}
for(i in 1:5){
result<-2*i
print(result)
}
data_boot1[i]=i*2
x<-c(data_boot1,data_boot2,data_boot3,data_boot4,data_boot5)
data_boot5
data_boot1 <- 0
data_boot2 <- 0
data_boot3 <- 0
data_boot4 <- 0
data_boot5 <- 0
x<-c(data_boot1,data_boot2,data_boot3,data_boot4,data_boot5)
i<-1
x[c(1:i)]=i*2
x
for(i in 1:5){
x[c(1:i)]=i*2
x
}
x
rm(list = ls())
data_boot1 <- 0
data_boot2 <- 0
data_boot3 <- 0
data_boot4 <- 0
data_boot5 <- 0
x<-c(data_boot1,data_boot2,data_boot3,data_boot4,data_boot5)
for(i in 1:5){
x[c(1:i)]=i*2
x
}
x
rm(list = ls())
data_boot1 <- iris[sample(1:nrow(iris), replace = T), ]
data_boot2 <- iris[sample(1:nrow(iris), replace = T), ]
data_boot3 <- iris[sample(1:nrow(iris), replace = T), ]
data_boot4 <- iris[sample(1:nrow(iris), replace = T), ]
data_boot5 <- iris[sample(1:nrow(iris), replace = T), ]
# Modeling
tree1 <- ctree(Species ~ ., data_boot1)
library(party)
library('party')
library(party)
install.packages("party")
library(party)
# Modeling
tree1 <- ctree(Species ~ ., data_boot1)
tree2 <- ctree(Species ~ ., data_boot2)
tree3 <- ctree(Species ~ ., data_boot3)
tree4 <- ctree(Species ~ ., data_boot4)
tree5 <- ctree(Species ~ ., data_boot5)
plot(tree1)
plot(tree5)
#predict
pred1 <- predict(tree1, iris)
pred2 <- predict(tree2, iris)
pred3 <- predict(tree3, iris)
pred4 <- predict(tree4, iris)
pred5 <- predict(tree5, iris)
# 각각의 예측 결과를 취합
test <- data.frame(Species = iris$Species, pred1, pred2, pred3, pred4, pred5)
head(test)
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
result <- c(result, rvalue)
}
return(result)
}
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
rvalue
result <- c(result, rvalue)
result
}
return(result)
}
test$result <- funcResultValue(test[ , 2:6])
test$result <- funcResultValue(test[ , 2:6])
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
print(rvalue)
result <- c(result, rvalue)
print(result)
}
return(result)
}
test$result <- funcResultValue(test[ , 2:6])
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
result <- c(result, rvalue)
}
print(result)
return(result)
}
test$result <- funcResultValue(test[ , 2:6])
test
head(test)
confusionMatrix(test$result, test$Species)
table(test$result, test$Species)
Confusion_Matrix<-table(test$result, test$Species)
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy<-Accuracy*100
Accuracy
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy
Accuracy<-Accuracy*100
Accuracy
rm(list = ls())
# bootstrap data 생성
idx1 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx2 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx3 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx4 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx5 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
train1<-iris[idx1, ]
train2<-iris[idx2, ]
train3<-iris[idx3, ]
train4<-iris[idx4, ]
train5<-iris[idx5, ]
test1<-iris[-idx1, ]
test2<-iris[-idx2, ]
test3<-iris[-idx3, ]
test4<-iris[-idx4, ]
test5<-iris[-idx5, ]
#install.packages("party")
library(party)
# Modeling
tree1 <- ctree(Species ~ ., data_boot1)
# Modeling
tree1 <- ctree(Species ~ ., train1)
tree2 <- ctree(Species ~ ., train2)
tree3 <- ctree(Species ~ ., train3)
tree4 <- ctree(Species ~ ., train4)
tree5 <- ctree(Species ~ ., train5)
plot(tree1)
plot(tree5)
plot(tree1)
plot(tree5)
#predict
pred1 <- predict(tree1, test1)
pred2 <- predict(tree2, test2)
pred3 <- predict(tree3, test3)
pred4 <- predict(tree4, test4)
pred5 <- predict(tree5, test5)
# 각각의 예측 결과를 취합
test <- data.frame(Species = iris$Species, pred1, pred2, pred3, pred4, pred5)
head(test)
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
result <- c(result, rvalue)
}
print(result)
return(result)
}
test$result <- funcResultValue(test[ ,2:6])
head(test)
Confusion_Matrix<-table(test$result, test$Species)
Accuracy<-sum(diag(Confusion_Matrix))/sum(Confusion_Matrix)
Accuracy<-Accuracy*100
Accuracy
# bootstrap data 생성
set.seed(2020)
idx1 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx2 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx3 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx4 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx5 <- sample(1:nrow(iris), size=nrow(iris)*0.8)
idx1
idx2
idx3
idx4
idx5
train1<-iris[idx1, ]
train1
test1<-iris[-idx1, ]
test2<-iris[-idx2, ]
test3<-iris[-idx3, ]
test4<-iris[-idx4, ]
test5<-iris[-idx5, ]
#install.packages("party")
library(party)
# Modeling
tree1 <- ctree(Species ~ ., train1)
tree2 <- ctree(Species ~ ., train2)
tree3 <- ctree(Species ~ ., train3)
tree4 <- ctree(Species ~ ., train4)
tree5 <- ctree(Species ~ ., train5)
plot(tree1)
plot(tree1)
plot(tree5)
#predict
pred1 <- predict(tree1, test1)
pred2 <- predict(tree2, test2)
pred3 <- predict(tree3, test3)
pred4 <- predict(tree4, test4)
pred5 <- predict(tree5, test5)
# 각각의 예측 결과를 취합
test <- data.frame(Species = iris$Species, pred1, pred2, pred3, pred4, pred5)
head(test)
# 5개 분류기의 결과를 취합하여 최종 결과를 voting
funcResultValue <- function(x) {
result <- NULL
for (i in 1:nrow(x)) {
xtab <- table(t(x[i, ]))
rvalue <- names(sort(xtab, decreasing = T)[1])
result <- c(result, rvalue)
}
print(result)
return(result)
}
test$result <- funcResultValue(test[ ,2:6])
head(test)
Confusion_Matrix<-table(test$result, test$Species)
Confusion_Matrix
test
rm(list = ls())
#iris 데이터 살펴보기
colnames(iris)
levels(iris$Species)
library(adabag)
install.packages("adabag")
library(adabag)
train <- sample(1:150, 100) #무작위로 100개 추출 (학습데이터)
iris.bagging <- bagging(Species ~.,data=iris[train, ],mfinal=5,  #5개 의사결정나무 이용
+  control=rpart.control(maxdepth=5, minsplit=5)) #최대깊이 5, 최소 노드 5
iris.bagging <- bagging(Species ~.,data=iris[train, ],mfinal=5,  #5개 의사결정나무 이용
control=rpart.control(maxdepth=5, minsplit=5)) #최대깊이 5, 최소 노드 5
iris.bagging$trees #각각 의사결정나무 결과보기
iris.bagging$trees[1] #각각 의사결정나무 결과보기
iris.bagging$trees #각각 의사결정나무 결과보기
iris.bagging$trees #각각 의사결정나무 결과보기
#bagging 모델을 구성하는 의사결정나무 그래프(첫번째)
> library(rpart.plot)
#bagging 모델을 구성하는 의사결정나무 그래프(첫번째)
library(rpart.plot)
rpart.plot(iris.bagging$trees[[1]])
#최종적으로 학습 데이터가 배깅 모델을 통해 분류된 결과는"iris.bagging$class" 로 확인할 수 있다.
#iris.bagging$importance를 통해 X인자의 중요도를 확인할 수 있습니다.
iris.bagging$class
iris.bagging$importance
#학습된 배깅 모델으로 Test셋 예측하기
predict(iris.bagging, iris[-train,])$class
tt <- table(iris$Species[-train], predict(iris.bagging, iris[-train,])$class)
#정분류율 및 오불류율 계산
sum(tt[row(tt) == col(tt)])/sum(tt) #정분류율
#정분류율 및 오불류율 계산
sum(tt[row(tt) == col(tt)])/sum(tt) #정분류율
1-sum(tt[row(tt) == col(tt)])/sum(tt) #오분류율
#정분류율 및 오불류율 계산
sum(tt[row(tt) == col(tt)])/sum(tt)) #정분류율
#정분류율 및 오불류율 계산
sum(tt[row(tt) == col(tt)])/sum(tt) #정분류율
#정분류율 및 오불류율 계산
ts<-sum(tt[row(tt) == col(tt)])/sum(tt) #정분류율
ts
th<-1-sum(tt[row(tt) == col(tt)])/sum(tt) #오분류율
th
#정오분류표 그래프화
library(ggplot2)
test <- iris[-train,]
test$pred <- predict(iris.bagging, iris[-train,])$class #예측된 분류 입력하기
ggplot(test, aes(Species, pred, color = Species)) +
+      geom_jitter(width = 0.2, height = 0.1, size=2) +
+      labs(title="Confusion Matrix",
+                 subtitle="Predicted vs. Observed from Iris dataset",
+                 y="Predicted",
+                 x="Truth")
ggplot(test, aes(Species, pred, color = Species)) +
geom_jitter(width = 0.2, height = 0.1, size=2) +
labs(title="Confusion Matrix",
subtitle="Predicted vs. Observed from Iris dataset",
y="Predicted",
x="Truth")
